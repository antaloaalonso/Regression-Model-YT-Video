{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries and sublibraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import input (x) and output (y) data, and asign these to df1 and df1\n",
    "\n",
    "df1 = pd.read_csv('StatsVideosXALL.csv')\n",
    "\n",
    "df2 = pd.read_csv('StatsVideosYALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into input (x) training and testing data, and ouput (y) training and testing data, \n",
    "# with training data being 80% of the data, and testing data being the remaining 20% of the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale both training and testing input data\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "\n",
    "X_test = preprocessing.scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the results of a learning rate of 100, 1000, and 10000 respectively, with all other parameters constant\n",
    "\n",
    "LR = [100,1000,10000]\n",
    "\n",
    "for i in LR:\n",
    "    #Defines linear regression model and its structure\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_shape=(3,)))\n",
    "    \n",
    "    #Compiles model\n",
    "    model.compile(Adam(lr=i), 'mean_squared_error')\n",
    "    \n",
    "    #Fits model\n",
    "    history = model.fit(X_train, y_train, epochs = 500, validation_split = 0.1,verbose = 0)\n",
    "    history_dict=history.history\n",
    "    \n",
    "    #Plots model's training cost/loss and model's validation split cost/loss\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values=history_dict['val_loss']\n",
    "    plt.figure()\n",
    "    plt.plot(loss_values,'bo',label='training loss')\n",
    "    plt.plot(val_loss_values,'r',label='val training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs and plots the performance of a model with the same parameters from before (and a learning rate of 10000), \n",
    "# but now with an activation function (Relu)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(3,), activation = 'relu'))\n",
    "model.compile(Adam(lr=10000), 'mean_squared_error')\n",
    "history = model.fit(X_train, y_train, epochs = 500, validation_split = 0.1,verbose = 0)\n",
    "\n",
    "history_dict=history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "plt.plot(loss_values,'bo',label='training loss')\n",
    "plt.plot(val_loss_values,'r',label='training loss val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs model (the one with the activation function, although this doesn't really matter as they perform the same) \n",
    "# with its current weights on the training and testing data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculates and prints r2 score of training and testing data\n",
    "print(\"The R2 score on the Train set is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines \"deep\" model and its structure\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_shape=(3,), activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(1,))\n",
    "model.compile(Adam(lr=0.003), 'mean_squared_error')\n",
    "\n",
    "# Runs model for 2000 iterations and assigns this to 'history'\n",
    "history = model.fit(X_train, y_train, epochs = 6000, validation_split = 0.2, verbose = 0)\n",
    "\n",
    "# Plots 'history'\n",
    "history_dict=history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "plt.plot(loss_values,'bo',label='training loss')\n",
    "plt.plot(val_loss_values,'r',label='training loss val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines \"deep\" model and its structure\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_shape=(3,), activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(1,))\n",
    "model.compile(Adam(lr=0.003), 'mean_squared_error')\n",
    "\n",
    "# Pass several parameters to 'EarlyStopping' function and assigns it to 'earlystopper'\n",
    "earlystopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "\n",
    "# Fits model over 2000 iterations with 'earlystopper' callback, and assigns it to history\n",
    "history = model.fit(X_train, y_train, epochs = 2000, validation_split = 0.2,shuffle = True, verbose = 0, \n",
    "                    callbacks = [earlystopper])\n",
    "\n",
    "# Plots 'history'\n",
    "history_dict=history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values=history_dict['val_loss']\n",
    "plt.plot(loss_values,'bo',label='training loss')\n",
    "plt.plot(val_loss_values,'r',label='training loss val')\n",
    "\n",
    "# Runs model with its current weights on the training and testing data\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculates and prints r2 score of training and testing data\n",
    "print(\"The R2 score on the Train set is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\n",
    "print(\"The R2 score on the Test set is:\\t{:0.3f}\".format(r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_train, y_train_pred,'*r')\n",
    "plt.plot(y_test, y_test_pred, '*g')\n",
    "plt.figure()\n",
    "for i in range(0,140):\n",
    "    plt.plot(i/100,i/100,'*b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
